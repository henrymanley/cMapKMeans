View(data)
set.seed(1)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
lg_mpg = glm(default  ~ income + balance,data = data, family = "binomial", subset = train)
lg_mpg = glm(default  ~ income + balance,data = data, family = "binomial", subset = training)
pred1 = predit(model1, newdata = test, type = "response")
pred1 = predict(model1, newdata = test, type = "response")
model1 = glm(default  ~ income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
pred1
results = pred1
results[results >0.5] = "Yes"
results
results[results <0.5] = "No"
results
data = Default
model0 = glm(default  ~ income + balance,data = data, family = "binomial")
set.seed(1)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results >0.5] = "Yes"
results[results <0.5] = "No"
results
model0 = glm(default  ~ income + balance,data = data, family = "binomial")
set.seed(1)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results >0.5] = "Yes"
results[results <=0.5] = "No"
results
results[results <=0.5] = "No"
results
data = Default
model0 = glm(default  ~ income + balance,data = data, family = "binomial")
set.seed(1)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results <=0.5] = "No"
results[results >0.5] = "Yes"
results
data = Default
model0 = glm(default  ~ income + balance,data = data, family = "binomial")
set.seed(1)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results <= 0.5] = "No"
results
results[results > 0.5 & results!="No" ] = "Yes"
results
missclass = results - train
missclass = (data$results - data$train)
missclass
missclass = results - train
missclass = (results - train)
missclass = mean(results != test$default)
missclass
seeds = c(1, 2, 3)
for (i in seeds){
set.seed(i)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results <= 0.5] = "No"
results[results > 0.5 & results!="No" ] = "Yes"
missclass = mean(results != test$default)
print(missclass)
}
for (i in seeds){
set.seed(i)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ student  + income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results <= 0.5] = "No"
results[results > 0.5 & results!="No" ] = "Yes"
missclass = mean(results != test$default)
print(missclass)
}
cv.mse = rep(0,5)
for (i in 1:5)
{
predcv <- glm(default  ~ student  + income + balance,data = data, family = "binomial", subset = training)
cv.mse[i] = cv.glm(training, predcv)$delta[1]
}
cv.mse
install.packages("Ecdat")
install.packages("boot")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("caret")
library(Ecdat)
library(boot)
library(dplyr)
library(caret)
library(ISLR)
cv.mse = rep(0,5)
for (i in 1:5)
{
predcv <- glm(default  ~ student  + income + balance,data = data, family = "binomial", subset = training)
cv.mse[i] = cv.glm(training, predcv)$delta[1]
}
cv.mse
predcv
cv.mse = rep(0,5)
for (i in 1:5)
{
model <- glm(default  ~ student  + income + balance,data = data, family = "binomial", subset = training)
pred = predict(model, newdata = test, type = "response")
results = pred
results[results <= 0.5] = "No"
results[results > 0.5 & results!="No" ] = "Yes"
missclass = mean(results != test$default)
cv.mse[i] = missclass
}
cv.mse
cv.mse = rep(0,5)
for (i in 1:5)
{
model <- glm(default  ~ poly(student, i)  + poly(income, i) + poly(balance, i),data = data, family = "binomial", subset = training)
cv.error = cv.glm(Default, model)
error = round(cv.error$delta,2)
cv.mse[i] = error
}
cv.mse
cv.mse = rep(0,5)
for (i in 1:5)
{
model <- glm(default  ~ poly(student, i)  + poly(income, i) + poly(balance, i),data = data, family = "binomial", subset = training)
}
cv.mse
cv.error = cv.glm(Default, model)
error = round(cv.error$delta,2)
cv.mse[i] = error
,
cv.mse = rep(0,5)
for (i in 1:5)
{
model <- glm(default  ~ poly(student, i)  + poly(income, i) + poly(balance, i),data = data, family = "binomial", subset = training)
cv.error = cv.glm(Default, model)
error = round(cv.error$delta,2)
cv.mse[i] = error
}
cv.mse = rep(0,5)
for (i in 1:5)
{
model <- glm(default  ~ poly(student, i)  + poly(income, i) + poly(balance, i),data = data, family = "binomial", subset = training)
cv.error = cv.glm(Default, model)
error = round(cv.error$delta,2)
}
cv.mse = rep(0,5)
for (i in 1:5)
{
model <- glm(default  ~ poly(student, i)  + poly(income, i) + poly(balance, i),data = data, family = "binomial", subset = training)
cv.error = cv.glm(Default, model)
error = cv.error$delta
cv.mse[i] = error
}
cv.mse
model <- glm(default  ~ poly(student, i)  + poly(income, i) + poly(balance, i),data = data, family = "binomial", subset = training)
v.mse = rep(0,5)
for (i in 1:5)
{
model <- glm(default  ~ poly(student, i)  + poly(income, i) + poly(balance, i),data = data, family = "binomial", subset = training)
cv.error = cv.glm(Default, model)
}
v.mse = rep(0,5)
for (i in 1:5)
{
model <- glm(default  ~ poly(student, i)  + poly(income, i) + poly(balance, i),data = data, family = "binomial", subset = training)
cv.error = cv.glm(Default, model)
}
cv.mse = rep(0,5)
for (i in 1:5)
{
model <- glm(default  ~ poly(student, i)  + poly(income, i) + poly(balance, i), data = data, family = "binomial", subset = training)
}
cv.mse = rep(0,5)
for (i in 1:5)
{
model <- glm(default  ~ poly(student, i)  + poly(income, i) + poly(balance, i), data = data, family = "binomial", subset = training)
}
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
model <- train(default ~ student  + income + balance, data = data, method = "glm", trControl = train.control)
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
model <- train(default ~ student  + income + balance, data = data, method = "glm", trControl = train.control)
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
model <- train(default ~ student  + income + balance, data = data, method = "glm", trControl = train.control)
library(caret)
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
library(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
library(caret)
library(ggplot2)
library(Ecdat)
library(boot)
library(caret)
library(ISLR)
library(ggplot2)
#1
data = Default
model0 = glm(default  ~ income + balance,data = data, family = "binomial")
seeds = c(1, 2, 3)
for (i in seeds){
set.seed(i)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results <= 0.5] = "No"
results[results > 0.5 & results!="No" ] = "Yes"
missclass = mean(results != test$default)
print(missclass)
}
for (i in seeds){
set.seed(i)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ student  + income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results <= 0.5] = "No"
results[results > 0.5 & results!="No" ] = "Yes"
missclass = mean(results != test$default)
print(missclass)
}
#error rate increases when including the dummy variable student
#With student
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
model <- train(default ~ student  + income + balance, data = data, method = "glm", trControl = train.control)
#Without student
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
model <- train(default ~ income + balance, data = data, method = "glm", trControl = train.control)
#error rate decreases when including the dummy variable student when usinf 5-fold cross validation
#2
library(MASS)
attach(Boston)
#a
mu = mean(medv)
# 22.53281
#b
se= sd(medv) / sqrt(dim(Boston)[1])
# The standard deviation of the mean is 0.4088611. This shows that
# there is little variation in sample mean, and that almost all data points
# will fall in a narrow range around the mean (narrow CI).
#c
# SE of mean
bootstrapmean = function(data, i) {
mu = mean(data[i])
return (mu)
}
boot(medv, bootstrapmean, 1000)
#The bootstrapped mean of the SE is a little higher (0.409 < 0.413), but
# not by much.
#d
#CI 95%
CI = t.test(medv)
CI_mu = c(22.53 -  0.4119*2, 22.53 + 0.4119*2)
# The bootstrapped CI is nearly the same as the t test's CI.
#e
med = median(medv)
# SE of median
bootstrapmedian = function(data, i) {
med = median(data[i])
return (med)
}
#f
boot(medv, bootstrapmedian, 1000)
#From the bootstrap, we find the estimated median to be 21.2 which is indentical to the "true" statistic.
# Similarly, there is a small standard error of 0.3874.
#g
p = quantile(medv, c(0.1))
#h
# 10th percentile
bootstrapquint = function(data, i) {
perc = quantile(data[i], c(0.1))
return (perc)
}
boot(medv, bootstrapquint, 1000)
#Again the boostrap method yields an estimate for the quintile that is nearly indentical
#to the "true" value. The standard error is quite small too, which further shows the strength
# of the bootstrap method in estimating these statistics.
library(boot)
library(ISLR)
library(ggplot2)
#1
data = Default
model0 = glm(default  ~ income + balance,data = data, family = "binomial")
seeds = c(1, 2, 3)
for (i in seeds){
set.seed(i)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results <= 0.5] = "No"
results[results > 0.5 & results!="No" ] = "Yes"
missclass = mean(results != test$default)
print(missclass)
}
for (i in seeds){
set.seed(i)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ student  + income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results <= 0.5] = "No"
results[results > 0.5 & results!="No" ] = "Yes"
missclass = mean(results != test$default)
print(missclass)
}
#error rate increases when including the dummy variable student
#With student
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
model <- train(default ~ student  + income + balance, data = data, method = "glm", trControl = train.control)
#Without student
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
model <- train(default ~ income + balance, data = data, method = "glm", trControl = train.control)
#error rate decreases when including the dummy variable student when usinf 5-fold cross validation
#2
library(MASS)
attach(Boston)
#a
mu = mean(medv)
# 22.53281
#b
se= sd(medv) / sqrt(dim(Boston)[1])
# The standard deviation of the mean is 0.4088611. This shows that
# there is little variation in sample mean, and that almost all data points
# will fall in a narrow range around the mean (narrow CI).
#c
# SE of mean
bootstrapmean = function(data, i) {
mu = mean(data[i])
return (mu)
}
boot(medv, bootstrapmean, 1000)
#The bootstrapped mean of the SE is a little higher (0.409 < 0.413), but
# not by much.
#d
#CI 95%
CI = t.test(medv)
CI_mu = c(22.53 -  0.4119*2, 22.53 + 0.4119*2)
# The bootstrapped CI is nearly the same as the t test's CI.
#e
med = median(medv)
# SE of median
bootstrapmedian = function(data, i) {
med = median(data[i])
return (med)
}
#f
boot(medv, bootstrapmedian, 1000)
#From the bootstrap, we find the estimated median to be 21.2 which is indentical to the "true" statistic.
# Similarly, there is a small standard error of 0.3874.
#g
p = quantile(medv, c(0.1))
#h
# 10th percentile
bootstrapquint = function(data, i) {
perc = quantile(data[i], c(0.1))
return (perc)
}
boot(medv, bootstrapquint, 1000)
#Again the boostrap method yields an estimate for the quintile that is nearly indentical
#to the "true" value. The standard error is quite small too, which further shows the strength
# of the bootstrap method in estimating these statistics.
sink("myfile.log", append=TRUE, split=TRUE)
library(boot)
library(caret)
library(ISLR)
library(ggplot2)
#1
data = Default
model0 = glm(default  ~ income + balance,data = data, family = "binomial")
seeds = c(1, 2, 3)
for (i in seeds){
set.seed(i)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results <= 0.5] = "No"
results[results > 0.5 & results!="No" ] = "Yes"
missclass = mean(results != test$default)
print(missclass)
}
for (i in seeds){
set.seed(i)
training =sample(1:nrow(data),nrow(data)/2, replace = FALSE)
train = data[training,]
test = data[-training,]
model1 = glm(default  ~ student  + income + balance,data = data, family = "binomial", subset = training)
pred1 = predict(model1, newdata = test, type = "response")
results = pred1
results[results <= 0.5] = "No"
results[results > 0.5 & results!="No" ] = "Yes"
missclass = mean(results != test$default)
print(missclass)
}
#error rate increases when including the dummy variable student
#With student
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
model <- train(default ~ student  + income + balance, data = data, method = "glm", trControl = train.control)
#Without student
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
model <- train(default ~ income + balance, data = data, method = "glm", trControl = train.control)
#error rate decreases when including the dummy variable student when usinf 5-fold cross validation
#2
library(MASS)
attach(Boston)
#a
mu = mean(medv)
# 22.53281
#b
se= sd(medv) / sqrt(dim(Boston)[1])
# The standard deviation of the mean is 0.4088611. This shows that
# there is little variation in sample mean, and that almost all data points
# will fall in a narrow range around the mean (narrow CI).
#c
# SE of mean
bootstrapmean = function(data, i) {
mu = mean(data[i])
return (mu)
}
boot(medv, bootstrapmean, 1000)
#The bootstrapped mean of the SE is a little higher (0.409 < 0.413), but
# not by much.
#d
#CI 95%
CI = t.test(medv)
CI_mu = c(22.53 -  0.4119*2, 22.53 + 0.4119*2)
# The bootstrapped CI is nearly the same as the t test's CI.
#e
med = median(medv)
# SE of median
bootstrapmedian = function(data, i) {
med = median(data[i])
return (med)
}
#f
boot(medv, bootstrapmedian, 1000)
#From the bootstrap, we find the estimated median to be 21.2 which is indentical to the "true" statistic.
# Similarly, there is a small standard error of 0.3874.
#g
p = quantile(medv, c(0.1))
#h
# 10th percentile
bootstrapquint = function(data, i) {
perc = quantile(data[i], c(0.1))
return (perc)
}
boot(medv, bootstrapquint, 1000)
#Again the boostrap method yields an estimate for the quintile that is nearly indentical
#to the "true" value. The standard error is quite small too, which further shows the strength
# of the bootstrap method in estimating these statistics.
library(Ecdat)
library(boot)
library(caret)
library(ISLR)
library(ggplot2)
#1
source("autoSort.py")
getwd()
setwd("/Users/henrymanley/desktop/classes/PAM4540/cMapKMeans
")
setwd("/Users/henrymanley/desktop/classes/PAM4540/cMapKMeans")
source("autoSort.py")
library("reticulate")
py_run_file("autoSort.py")
Y
py_run_file("autoSort.py")
n
reticulate::use_condaenv("py37")
py_run_file("autoSort.py")
